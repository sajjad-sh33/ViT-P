train:
  # batch_size_per_gpu: 32
  batch_size_per_gpu: 20
  dataset_path: "ADE20k"
  # OFFICIAL_EPOCH_LENGTH: 320
  OFFICIAL_EPOCH_LENGTH: 640
student:
  arch: vit_large
  patch_size: 14
  num_points: 250
  num_classes: 150
  pretrained_weights: './checkpoint.pth'
  # pretrained_weights: './dinov2_vitl14_pretrain.pth'
  # drop_path_rate: 0.4
  # ffn_layer: swiglufused
  # block_chunks: 4
optim:
  epochs: 40
  warmup_epochs: 1
  lr: 6e-3
crops:
  # global_crops_size: [756, 756]
  global_crops_size: [518, 518]